7CS039 Statistics Data Science
Week 4 Hypothesis Testing
1 Introduction
The idea behind all statistical hypothesis testing is as follows:
• We have a theory (hypothesis) which we believe to be true (called the alternative
hypothesis H ).
1
• We only accept that it is true if we can show that the opposite (null hypothesis H )
0
is very unlikely to be true.
How unlikely H need be before we reject it is largely a matter for the researcher to
0
determine, but the standard is that we only reject H , and accept H if the probability
0 1
that we would obtain a sample like that observed if the null hypothesis were true is
at most 0.05. This is known as a Level of Significance of 0.05, we often write this as
α = 0.05. Sometimes if we wish to be extra sure that we do not come to the conclusion
that our alternative hypothesis is true, when in fact it is false, (i.e. commit a type one
error), we set a level of significance of 0.02 or 0.01, or if we need not be so certain that
our conclusions are correct, we might let α = 0.10.
2 General Setup
Some of the most common type of hypotheses that are tested are
• the mean of a population is equal to some given value.
• the mean of a population is greater/less than a given value.
• the means of two different populations are different.
Let’s look at a simple example to get a better understanding of the general setup.
Example
Suppose that we wish to determine the mean lifespan of a given brand of energy
saving lightbulb. The manufacturer claims that the mean µ = 600 hours. We don’t
believe this and we have a suspicion that the mean is actually less than µ = 600,
1
Example ctd.
Our null and alternative hypothesis are as follows
• H - the mean is as the manufacturer say µ = 600 hours. (we want to reject
0
this)
• H - the mean less than the manufacturer claims i.e. µ < 600 hours. (we
1
want to accept this)
This is an example of a one-tailed hypothesis test, H is false if the true value of µ
0
lies to the left side (one side) of the hypothesized value of µ.
We decide to let α = 0.05. Thus we are only going to conclude that our alternative
hypothesis is true if, in some sense, we can show that the probability that µ = 600
is less than 0.05.
Suppose now for a moment that the mean lifespan of one of these lightbulbs is 600
hours as the manufacturer claims. This implies that about half the lightbulbs will
last longer than 600 hours, and that about half will last less than 600 hours, thus
if we take a sample of lightbulbs and find that x¯ = 599.9 we cannot conclude that
H : µ = 600 is false because half of the time we would get a sample mean less than
0
the population mean anyhow, and a difference of 0.1 means nothing. On the other
hand, if we take a sample of bulbs and find x¯ = 590 it is less likely that the mean
of the population from which the sample is drawn is equal to 600, and if x¯ = 500
it is even less likely. The question is: how far away from 600 need x¯ be before we
can conclude that the probability that H : µ = 600 is true is less than 0.05? The
0
answer to this question will depend on two things:
• The standard deviation, σ, of the population from which the sample was
taken. The larger the standard deviation the more spread out the data will
be. Hence if in this case σ = 20 a difference of, say, 10 between µ and x¯ is
more significant than it would be if σ = 50.
• The size of the sample: the larger the sample, the more accurate the results,
thus a difference of, say, 10 between µ and x¯ is more significant if the sample
size is 400 than if the sample size is 100.
3 –tests
Z
Suppose we were to take a theoretically infinite number of samples of size n from data
with mean µ and standard deviation σ, and record the mean of each sample. Then,
with very very few exceptions, we would find that the standard deviation of these sample
means is itself normally distributed with mean µ and standard deviation √ σ .This result
n
is known as the central limit theorem. The standard deviation of the sample means is
referred to as the standard error of the mean. Similarly, if the lower quartile of each
sample was calculated and recorded, and the standard deviation of all the lower quartiles
2
was calculated, this would be the standard error of the lower quartiles, and similarly for
any statistic.
3.1 Z–test for a single population mean
Theoretically we should only use the Z-test for a single population mean (also known as
the single sample Z-test) if we know the standard deviation (σ) of the population from
which we took the sample. In practice we may also use the the Z-test for a single
population mean if the sample size is greater than about thirty as then the sample
standard deviation is usually a good approximation for the the standard deviation of
the data from which the sample was taken. In this case we substitute s for σ in the
formula below. The Z-test for a single population mean works as follows:
Definition 3.1. Let
x¯−µ
z = √ 0
obs
σ/ n
• We reject H : µ = µ in favour of H : µ ̸= µ if |z | > z (Two tailed test)
0 0 1 0 obs crit
• We reject H : µ = µ in favour of H : µ < µ if z < z ((Lower) One tailed
0 0 1 0 obs crit
test)
• We reject H : µ = µ in favour of H : µ > µ if z > z ((Upper) One tailed
0 0 1 0 obs crit
test)
Where z is the critical value of z,
crit
The value of z depends upon the level of significance, and whether the test is one
crit
or two tailed. The most frequently used values are summarized in Table 1 below.
Table 1: Critical Values of Z
ONE TAILED TWO TAILED
H α z H α z H α z
1 crit 1 crit 1 crit
H : µ < µ 0.01 −2.33 H : µ > µ 0.01 2.33 H : µ ̸= µ 0.01 2.58
1 0 1 0 1 0
H : µ < µ 0.02 −2.05 H : µ > µ 0.02 2.05 H : µ ̸= µ 0.02 2.33
1 0 1 0 1 0
H : µ < µ 0.05 −1.64 H : µ > µ 0.05 1.64 H : µ ̸= µ 0.05 1.96
1 0 1 0 1 0
H : µ < µ 0.10 −1.28 H : µ > µ 0.10 1.28 H : µ ̸= µ 0.10 1.64
1 0 1 0 1 0
Example
SupposethatwewishtotestwhetherornotH : themeanheightofWolverhampton
1
men is greater than 69 inches i.e µ > 69. We take a sample of size n = 60 and find
that the mean of this sample is x¯ = 70, with a standard deviation of s = 2 inches.
Is this sufficient evidence to claim that H is true α = 0.05?
1
3
Example ctd.
We must test H : µ = 69, at α = 0.05. Here
0
70−69
z = √ = 3.87.
obs
2/ 60
We don’t know the value of σ so we can substitute s = 2 as the sample is large.
Since z = 3.87 > 1.64 = z we can reject H , and thus conclude that the
obs crit 0
evidence is sufficient to conclude that the mean height of Wolverhampton men is
greater than 69 inches.
3.2 Z-test for the difference between two population
means
The Z-test for the difference between two population means, also known as the two-
sample Z-test, is used to test
H : µ ̸= µ or H : µ < µ or H : µ > µ
1 1 2 1 1 2 1 1 2
Where µ and µ are the means of two different populations. For the two sample Z–test
1 2
x¯ −x¯
1 2
z =
obs (cid:113)
σ1 2 + σ2 2
n1 n2
The values of z are exactly the same as for the one sample Z-test, see Table 1. The-
crit
oretically we should only use the two–sample Z–test if the variances σ2 and σ2 of the
1 2
populations from which both samples were drawn is known, but in practice we may use
the test provided both samples are large, which is usually taken to mean greater than 30,
in which case we substitute the population variances by the sample variances.
Example
Suppose that we wish to test H : the mean height of Wolverhampton women and
1
Birmingham women differs. Thus the null hypothesis is H : µ = µ , (where
0 1 2
µ and µ are the population mean heights of Wolverhampton and Birmingham
1 2
women respectively). A sample of 50 Wolverhampton women is taken, and it is
found that x¯ = 64.3 inches, with s = 3 inches. A sample of 60 Birmingham
1 1
women is taken, and it is found that x¯ = 64.8 inches, with s = 2 inches. Can we
2 2
reject the above null hypothesis at α = 0.05?
4
Example ctd.
Here:
64.3−64.8
z = = −1.01
obs (cid:113)
32 + 22
50 60
Note that this is a two–tailed test at α = 0.05, thus z = 1.96. Thus: |z | =
crit obs
1.01 ̸>1.96 = z Hence there is not sufficient evidence to reject H , i.e., the
crit 0
difference of half an inch in the mean heights of the two samples of women is not
sufficient a large enough difference to be able to conclude with 95% certainty that
the mean heights of the populations from which the samples were drawn differs.
4 –tests....when is unknown
t σ
To use a Z-test we should know the standard deviation of the population from which
we draw our sample(s). If the sample size is large, i.e. approximately > 30 we may still
use the Z-test as the standard deviation of the sample (s) will closely approximate the
standard deviation (σ) of the data from which the sample was taken; what if the sample
size is ≤ 30? We use a t–test. At first glance, the t and z test look very similar. We look
at the “one sample t–test” first.
4.1 t-test for a single population mean
This time we have
x¯−µ
t = √ 0
obs
s/ n
There are many different t–distributions (i.e. no standard one) so it is impossible to
publish complete tables of all of them. In practise we’ll use R so no need to worry.
Example
A car sales person claims that a particular model of car gives a mean mileage that
differs from 20 miles per gallon. To test this claim an experiment was carried out
in which a random sample of 10 such cars were each run on one gallon of petrol.
The results were as follows.
24,23,18,22,19,19,22,18,18,22
Are the sales person’s claims justified at α = 0.05 if we are testing H : µ = 20
0
against
i H : µ > 20,
1
ii H : µ ̸= 20?
1
5
Example ctd.
It is easily shown that x¯ = 20.5, s = 2.32. Here n = 10.
Thus: t obs = 20.5− √ 20.0 = 0.682
2.32/ 10
i) From R we have t = 1.833 thus
crit
t = 0.682 ≯ 1.833 = t
obs crit
Hence we may not reject H .
0
ii) This is a two tailed test and from R we have t = 2.262.
crit
Hence as:
|t | = 0.682 ≯ 2.262 = t
obs crit
we do not reject H .
0
5 -values
p
In problems such as these we often accompany the calculated test statistic with the
corresponding p-value. In general the p-value may be defined as follows.
Definition 5.1. Corresponding to an observed value of a test statistic the p-value is the
lowest level of significance for which the null hypothesis could have been rejected.
Example (again)
A car sales person claims that a particular model of car gives a mean mileage that
differs from 20 miles per gallon. To test this claim an experiment was carried out
in which a random sample of 10 such cars were each run on one gallon of petrol.
The results were as follows.
24,23,18,22,19,19,22,18,18,22
Are the sales person’s claims justified at α = 0.05 if we are testing H : µ = 20
0
against
i H : µ > 20,
1
ii H : µ ̸= 20?
1
6
Example (again) ctd.
Now we use R to calculate the p-values.
i H : µ > 20,
1
> mileage<-c(24,23,18,22,19,22,19,18,18,22)
> t.test(mileage,mu=20,alternative="greater")
Thep-valueis0.2565
which is greater than α = 0.05 so we can’t reject H .
0
ii H : µ ̸= 20?
1
> t.test(mileage,mu=20,alternative="two.sided")
Thep-valueis0.5129
which is greater than α = 0.05 so we can’t reject H .
0
In practise we will use p-values as often as we can.
6 Other Similar Tests
There are a variety of other tests similar to the above including
• The Independent Samples t-test.
• The Paired Samples t-test.
• Mann-Whitney test.
7
• Chi–Square Tests.
We will look at some of these in the lab session this week.
8