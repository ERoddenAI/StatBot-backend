7CS039 Statistics for Data Science
Week 3 Correlation & Regression
1 Introduction
It frequently happens that two different “measurements” (x and y) are made for each
“subject” in a study. Such data may be displayed in a “scatter diagram” (also known as
a scatterplot, scattergram, or scattergraph), an example is shown in Figure 1
Figure 1: Scatterplot or scatter diagram
N.B. If one variable comes first in time, or one is independent and one dependent
(not necessarily causally), the earlier or independent variable, usually (but far from ex-
clusively) called x, is drawn on the horizontal axis; the later or dependent variable is
(usually) called y and is drawn on the vertical axis. It is important to note that often
which variable is “independent” and which dependent is quite arbitrary. For example, if
we were to have data relating to the heights of 25 married couples it is not that either
“height of husband” depends on “height of wife” or vice versa.
In such settings, two (related but distinct) questions arise naturally:
Q1. Is there a linear relationship between x and y? How strong is any such relationship?
Q2. Assuming there is a linear relationship, what is it?
1
The first question relates to “correlation” and the second question relates to “regres-
sion”.
Both ideas (correlation and regression) can be extended to more than two variables
- , and to non-linear relationships, i.e. to relationships other than straight lines, this is
known as multiple and curvilinear regression/ correlation.
2 Correlation
Various measures of correlation have been developed for different kinds of data. All run
from +1 (exact direct relationship, as x increases y also increases) to −1 (exact reverse
relationship, as x increases y decreases and vice versa). A correlation coefficient of 0
indicates no linear relationship.
The most common correlation coefficient is Pearson’s product-moment correlation
coefficient. It is denoted by the Greek letter ρ (if we are referring to the population
correlation), or by r if we are referring to a correlation calculated from a sample in order
to estimate the population correlation. (This requires interval or ratio level data). The
sample correlation may be calculated by:
(cid:80)n
(X −X
¯
)(Y −Y
¯
)
r = i=1 i i
(cid:112)(cid:80)n (X −X ¯ )2 (cid:112)(cid:80)n (Y −Y ¯ )2
i=1 i i=1 i
Nowadays however it is invariably calculated using a computer package, many calcu-
lators have functions to calculate the correlation coefficient also.
Example
For example, consider the following table which records the amounts of crates of
beer drank in a given bar, and the temperature (in Fahrenheit), over a ten day
period.
Day 1 2 3 4 5 6 7 8 9 10
Temperature 55 60 60 70 62 64 68 71 63 62
Beer Sales 40 41 43 49 44 45 49 50 44 43
2
Example ctd.
Let us look at a scatter plot of the variables “temperature” and “beer sales”.
Figure 2: Strong, Positive, Linear Correlation
From the scatter plot we see that:
• Beer sales increase as temperature increases. [Positive correlation]
• If we drew the straight line on the scatter plot that best fitted the points this
line would nearly pass through all the points. [Strong linear correlation]
Scatterplots for “temperature” and “coffee sales” and “temperature” and “bread sales”
might be as follows:
Figure 3: Strong, Negative, Linear Correlation
3
Figure 4: Little or No Linear Correlation
Note that two variables that may be weakly linearly correlated may be strongly correlated
some other way. e.g. the variables below are related by an equation of the form Y =
aX2 +bX +c+ε, hence they are strongly quadratically correlated.
Figure 5: Strong Quadratic Correlation (but negligible linear correlation)
In layman’s terms, two variables are strongly correlated if knowledge of the value of
one variable enables precise prediction of the value of another, and weakly correlated if
knowledge of the value of one variable enable some, but poor, prediction of the value of
the other.
4
2.1 Correlation Does not (necessarily) Imply Causation
“Correlation does not imply causation” is a phrase used in science and statistics to em-
phasize that correlation between two variables does not automatically imply that one
causes the other. The opposite belief, correlation proves causation, is a logical fallacy by
which two events that occur together are claimed to have a cause-and-effect relationship.
For example, in the UK there is a moderate negative correlation between temperature
and sales, in general there is a higher volume of sales when it is colder. This is however
due to cold weather tending to occur around Christmas. Similarly, until recently there
was a strong negative correlation between the number of televisions in a country and the
infant mortality rate in that country, but this was a consequence of both being influenced
by poor economic conditions.
2.2 (Pearson’s) Correlation Coefficient
We most commonly measure correlation using Pearson’s correlation coefficient. Pearson’s
correlation coefficient should only be used between two variables that are measured on an
interval scale. Other versions exist for when this is not the case, but we shall not cover
them in this course.
2.2.1 Some properties of Pearson’s Correlation Coefficient
(i) −1 ≤ r ≤ 1
(ii) (a) r < 0 ←→ negative correlation
(b) r > 0 ←→ positive correlation
(c) r = 0 ←→ zero correlation
(iii) (a) r = 1 ←→ perfect positive correlation
(b) r = −1 ←→ perfect negative correlation
(iv) r isthesample(linear)correlationcoefficient, andhenceitwillvaryaccordingtothe
particular sample chosen. The population (linear) correlation coefficient is denoted
by the Greek letter ρ, (rho). Methods exist for estimating confidence intervals for
ρ.
For example, using any statistical software program we may determine that for the
“beer sales example” r = 0.974, indicating strong, positive, linear correlation.
5
Example
Blood is a mixture of cells and plasma. The packed cell volume (PCV) is a mea-
surement of the proportion of blood that is made up of cells. The value is expressed
as a percentage or fraction of cells in blood. For example, a PCV of 40% means
that there are 40 millilitres of cells in 100 millilitres of blood. Haemoglobin (Hb)
is a protein found in red blood cells in your blood and is a good indication of
your blood’s ability to carry oxygen throughout your body. A natural question
is whether there is a relationship between a person’s age, their PCV levels and
their Hb level. Table 1 contains relevant data, Table 2 describes the correlations
between the variables and Figure 6 contains the scatterplots. We see that their is
a moderate-strong linear correlation between PCV and Age, the other correlations
being weak.
Table 1: Data from Campbell et al (1985)
Subject No. Age Hb (g/dl) PCV (%)
1 20 11.1 35
2 22 10.7 45
3 25 12.4 47
4 28 14.0 50
5 28 13.1 31
6 31 10.5 30
7 35 12.5 33
8 38 13.5 35
9 40 13.9 40
10 45 15.1 45
Table 2: Correlations
Age with Hb r = 0.7242
Age with PCV r = −0.0494
Hb with PCV r = 0.3654
6
Figure 6: Scatterplots associated with Table 1
3 Ordinary Least Squares Regression
Any straight line has equation of the form y = a + bx. The line is determined by the
values of a (the intercept) and b (the slope/gradient). Ordinary least squares regression
aims to find the “best” values of a and b to “fit” a given set of points. There are various
methods for determining this, but by far the most common method is to choose the “best”
line according to the principle of least squares so as to minimize “the sum of the squares
of the residuals”, a residual being the difference between an observed value and the value
predicted by the regression equation. There are various preconditions that the residuals
should meet but we will not go into them here. In the past the values of a and b were
calculated by hand using:
(cid:80)
(x−x¯)(y −y¯)
b = a = y¯−bx¯
(cid:80)
(x−x¯)
but nowadays they are invariably calculated using software packages such as R. If R
is used to find the regression line associated with Age versus Hb from the example of
Section 2.2.1 the following analysis is obtained:
These are the values for a and b. We can get some more details by doing:
Note the following:
• The variable being predicted, here Hb is the response variable. The variable used
for the prediction is the independent or predictor variable, or as a covariate.
7
• Hb = 8.42+0.136Age. The estimated mean value of Hb for a given value of Age is
predicted to be that obtained by plugging Age into the equation, e.g. for Age= 40
we predict that, on average, Hb = 8.423+(0.13645×40) = 13.881
• Residual standard error= 1.123, this is the standard deviation of the residuals.
More than this this implies that all the data is conditionally normally distributed
with mean as predicted by the equation, and standard deviation 1.123. e.g. The Hb
of40yearoldsispredictedtobenormallydistributedwithmean13.88andstandard
deviation 1.123. The Hb of 21 year olds is predicted to be normally distributed with
mean 11.29 and standard deviation 1.123.
• Note that from Table 1 we see that the minimum age is 20 and the maximum
45. We should be very cautious in making predictions outside of this age range
(“extrapolating outside of the range of the observed data”) as we cannot be sure
that the pattern observed within this range will continue outside it. For example,
if we plug Age= 10 in the regression equation we predict that the average value of
Hb is 9.787, but it may well be the case that the relationship between Age and Hb
differs in childhood to adulthood.
• The coefficient of Age is (estimated to be) 0.13645. This implies that for each unit
increase in the value of age Hb is predicted to increase by, on average, 0.13645.
• The (estimated) constant “coefficient” (often referred to as the “intercept”) is 8.423.
Usually this has no interpretation other than if we were to extend the regression
line until it intercepts the y axis, it would intercept at y = 8.423.
• R-squared=0.5244. This may be interpreted as saying that 52.4% of the variation
in Hb is attributable to variation in age, the other 47.6% being attributable to other
things not considered. This is also the square of the correlation coefficient; thus we
√
could calculate that r = 0.524 = 0.724. (As r is clearly positive, the correlation
is the positive square root.)
8
Exercise
A commonly used measure of lung function is “FEV1” which stands for “forced
expiratory volume in one second”.
(i) Plot the data of Table 3 as a scatter diagram with height (cm) as x.
Table 3: Height and FEV1
Height (cm) FEV1 (litres) Height (cm) FEV1 (litres)
164.0 3.24 176.0 3.75
167.0 3.24 177.0 4.05
170.4 3.19 177.4 3.60
171.2 3.42 180.7 4.80
171.3 3.20 181.0 3.96
172.0 3.60 183.1 4.78
172.0 3.78 183.6 4.56
174.0 4.32 183.7 4.68
(ii) Briefly explain the statement “the correlation between Height and FEV1 is
0.861”.
(iii) The R output when FEV1 is regressed on height is:
What is the regression equation? Interpret the coefficients of −10.7476 and
0.083487.
(iv) Use the regression equation to predict the FEV1 of a student 174 cm tall.
Briefly explain why your answer differs from the FEV1 of 4.32 litres observed
for the student of height 174 cm in Table 3.
(v) What is the predicted distribution of FEV1 for students that are 174 cen-
timetres tall?
9
(vi) Use the regression equation to predict the FEV1 of a student 205 cm tall.
Comment on the reliability of this prediction.
Solution
(i)
Figure 7: Question 1
(ii) Fairly strong positive relationship, as height increases so does FEV1, we may
make reasonably precise predictions of the value of FEV1 for a given value of
height.
(iii) The line of best fit (according to the “principle of least squares") is
FEV1 = −10.7+0.0835Height
a = −10.7476 is the intercept, i.e. the value of FEV1 at which the line,
continued back to height = 0, would cross the vertical axis.
b = 0.083487 is the gradient, i.e. the estimated mean increase in FEV1 for
each 1cm increase in height.
(iv) If x = 174, yˆ= −10.748+(0.08349×174) = 3.78, i.e. 3.78 litres
This is the best prediction, based on the available data, of the mean FEV1 of
students 174 cm tall. Any particular student of that height may have FEV1
above or below the average.
(v) Normally distributed with mean 3.78 and standard deviation 0.3083.
(vi) x = 205 ⇒ y = 6.367 i.e 6.37 litres.
Very unreliable, as we have no information for anybody over 183.7 cm tall.
10